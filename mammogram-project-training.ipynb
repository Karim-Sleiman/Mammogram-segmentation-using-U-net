{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the U-net model to segment mammogram images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-08T12:27:50.600279Z",
     "iopub.status.busy": "2024-01-08T12:27:50.599031Z",
     "iopub.status.idle": "2024-01-08T12:28:04.697572Z",
     "shell.execute_reply": "2024-01-08T12:28:04.696789Z",
     "shell.execute_reply.started": "2024-01-08T12:27:50.600232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for deep learning model building\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, Conv2D, Dropout, UpSampling2D, concatenate, Add, Multiply, Input, MaxPool2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "# Import necessary libraries for logic, tables, open cv and pydicom for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import pydicom\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import albumentations as A\n",
    "import plistlib\n",
    "from skimage.draw import polygon\n",
    "import re\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "\n",
    "# from skimage.morphology import label  # You've commented this line, so I'm leaving it out\n",
    "from tensorflow import keras\n",
    "from skimage.color import rgb2gray\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T00:45:14.605855Z",
     "iopub.status.busy": "2024-01-08T00:45:14.605198Z",
     "iopub.status.idle": "2024-01-08T00:45:14.614763Z",
     "shell.execute_reply": "2024-01-08T00:45:14.613593Z",
     "shell.execute_reply.started": "2024-01-08T00:45:14.605822Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure deep learning specific libraries are imported\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Add\n",
    "from keras.layers import Multiply\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import backend as K \n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Metrics\n",
    "from keras.metrics import MeanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T00:45:18.777740Z",
     "iopub.status.busy": "2024-01-08T00:45:18.777341Z",
     "iopub.status.idle": "2024-01-08T00:45:18.782422Z",
     "shell.execute_reply": "2024-01-08T00:45:18.781281Z",
     "shell.execute_reply.started": "2024-01-08T00:45:18.777710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get Data sets from the InBreast2012 Data-set on kaggle\n",
    "DCM_PATH = '/kaggle/input/inbreast2012/INbreast Release 1.0/AllDICOMs/'\n",
    "XML_PATH = '/kaggle/input/inbreast2012/INbreast Release 1.0/AllXML/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of patient IDs for the INBREAST dataset\n",
    "MASS_PATIENT_ID = ['53586896', '22580192', '22614236', '22580098', '24055445', '30011674', '20586934', '22670465', '24055502', '22670673', '20587612', '22614568', '20587902', '22614522', '50995789', '24055464', '20588216', '51049053', '53582656', '20588562', '27829188', '22614431', '22580341', '22613822', '24065584', '50997515', '51049107', '22580367', '22580244', '50996352', '22670147', '22580732', '50999008', '24065707', '22614127', '20588334', '20588536', '24065530', '22670324', '20586908', '30011507', '27829134', '53581406', '50998981', '20586986', '22678787', '50997461', '53580804', '22579730', '22670094', '53580858', '53586869', '50995762', '24065251', '20587810', '53581460', '22670855', '22580706', '30011553', '22670809', '22580419', '24055355', '53587014', '50994408', '22614379', '22670278', '24065289', '22614074', '24055274', '22670511', '50994354', '20587928', '22580393', '22580654', '20588046', '50994273', '20587758', '24065761', '22427751', '20587664', '50999432', '22580680', '22580038', '53587663', '20588308', '20588680', '30011727', '22678833', '22427705', '22614266', '22613650', '50999459', '24055483', '22678694', '20587994', '22678646', '53582683', '20586960', '51048765', '22670620', '22613770', '22427840', '20588190', '53586960', '50996406', '22613702', '51048738']\n",
    "\n",
    "seed = 40  # Seed to generate a different dataset\n",
    "\n",
    "def load_inbreast_mask(mask_path, imshape=(4084, 3328)):\n",
    "    \"\"\"\n",
    "    This function loads an OsiriX XML region as a binary numpy array for the INBREAST dataset.\n",
    "\n",
    "    Args:\n",
    "    @mask_path : Path to the XML file\n",
    "    @imshape : The shape of the image as an array e.g. [4084, 3328]\n",
    "\n",
    "    Returns:\n",
    "    numpy array where each mass has a different number ID.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_point(point_string):\n",
    "        # Helper function to extract x, y coordinates from a string\n",
    "        x, y = tuple([float(num) for num in point_string.strip('()').split(',')])\n",
    "        return y, x\n",
    "\n",
    "    i = 0  # Counter for the number of masses detected\n",
    "    mask = np.zeros(imshape)  # Initialize an array for the mask\n",
    "\n",
    "    with open(mask_path, 'rb') as mask_file:\n",
    "        plist_dict = plistlib.load(mask_file, fmt=plistlib.FMT_XML)['Images'][0]\n",
    "        numRois = plist_dict['NumberOfROIs']  # Number of ROIs in the XML file\n",
    "        rois = plist_dict['ROIs']  # Extract all ROIs\n",
    "        assert len(rois) == numRois  # Ensure consistency in ROI count\n",
    "\n",
    "        for roi in rois:\n",
    "            numPoints = roi['NumberOfPoints']  # Number of points in the ROI\n",
    "            if roi['Name'] == 'Mass':  # Check if the ROI is a 'Mass'\n",
    "                i += 1  # Increment the mass counter\n",
    "                points = roi['Point_px']  # Extract points of the mass\n",
    "                assert numPoints == len(points)  # Ensure consistency in point count\n",
    "\n",
    "                # Load and map points to the mask\n",
    "                points = [load_point(point) for point in points]\n",
    "                if len(points) <= 2:\n",
    "                    for point in points:\n",
    "                        mask[int(point[0]), int(point[1])] = i  # Mark points on the mask\n",
    "                else:\n",
    "                    x, y = zip(*points)\n",
    "                    x, y = np.array(x), np.array(y)\n",
    "                    poly_x, poly_y = polygon(x, y, shape=imshape)  # Create a polygon from points\n",
    "                    mask[poly_x, poly_y] = i  # Fill the polygon on the mask with the mass ID\n",
    "\n",
    "    return mask  # Return the generated mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T01:02:06.504177Z",
     "iopub.status.busy": "2024-01-08T01:02:06.503781Z",
     "iopub.status.idle": "2024-01-08T01:02:06.512699Z",
     "shell.execute_reply": "2024-01-08T01:02:06.511481Z",
     "shell.execute_reply.started": "2024-01-08T01:02:06.504148Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dicom(dicom_path):\n",
    "    # Load DICOM file\n",
    "    dicom = pydicom.dcmread(dicom_path)\n",
    "\n",
    "    # Extract pixel data from DICOM file\n",
    "    pixel_data = dicom.pixel_array\n",
    "    return pixel_data\n",
    "\n",
    "def histogram_equalization_png(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Apply histogram equalization\n",
    "    img_equalized = cv2.equalizeHist(img)\n",
    "    return img_equalized\n",
    "\n",
    "def histogram_equalization(img):\n",
    "    m = int(np.max(img))\n",
    "    hist = np.histogram(img, bins=m+1, range=(0, m+1))[0]\n",
    "    # bước 1: tính pdf\n",
    "    hist = hist/img.size\n",
    "    # bước 2: tính cdf\n",
    "    cdf = np.cumsum(hist)\n",
    "    # bước 3: lập bảng thay thế\n",
    "    s_k = (255 * cdf)\n",
    "    # ảnh mới\n",
    "    img_new = np.array([s_k[i] for i in img.ravel()]).reshape(img.shape)\n",
    "    return img_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "DCM_PATH = '/kaggle/input/inbreast2012/INbreast Release 1.0/AllDICOMs/'\n",
    "Y_TRAIN_PATH = '/kaggle/input/inbreast2012/INbreast Release 1.0/AllXML/'\n",
    "\n",
    "# List all X_train files\n",
    "X_train_files = os.listdir(DCM_PATH)\n",
    "\n",
    "# Initialize lists for X_train and Y_train data\n",
    "X_train_data = []\n",
    "Y_train_data = []\n",
    "\n",
    "# Define a regular expression pattern to match digits before underscore\n",
    "pattern = re.compile(r'^(\\d+)_')\n",
    "\n",
    "# Iterate through X_train files\n",
    "for x_file in X_train_files:\n",
    "    match = pattern.match(x_file)\n",
    "    if match:\n",
    "        file_id = match.group(1)\n",
    "\n",
    "        # Find the corresponding Y_train file in the Y_TRAIN_PATH folder\n",
    "        y_file_candidates = [y_file for y_file in os.listdir(Y_TRAIN_PATH) if y_file.startswith(file_id)]\n",
    "\n",
    "        if y_file_candidates:\n",
    "            # Assuming you want to use the first matching Y_train file\n",
    "            y_file = y_file_candidates[0]\n",
    "            y_file_path = os.path.join(Y_TRAIN_PATH, y_file)\n",
    "\n",
    "            # Load X_train and Y_train data (adjust this part based on your data format)\n",
    "            x_data = load_dicom(os.path.join(DCM_PATH, x_file))\n",
    "#             print(x_data.shape)\n",
    "            y_data =load_inbreast_mask( y_file_path,  imshape=(x_data.shape[0], x_data.shape[1]))\n",
    "            if y_data.max()<1: # if no lesion\n",
    "                continue #skip\n",
    "#             print(y_data.shape)\n",
    "            # resize the data\n",
    "            x_data_resized = cv2.resize(x_data, (256, 256))\n",
    "            y_data_resized = cv2.resize(y_data, (256, 256))\n",
    "\n",
    "            # Append resized data to respective lists\n",
    "            X_train_data.append(x_data_resized)\n",
    "            Y_train_data.append(y_data_resized)\n",
    "        else:\n",
    "            print(f\"No corresponding Y_train file found for X_train file '{x_file}' with ID '{file_id}'.\")\n",
    "            \n",
    "X_train_data = np.array(X_train_data)\n",
    "Y_train_data = np.array(Y_train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the first 20 pairs of training data (images and corresponding masks)\n",
    "for i, (x_data, y_data) in enumerate(zip(X_train_data[:20], Y_train_data[:20])):\n",
    "    \n",
    "    # Create a figure to display the current pair of images\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot the original image (x_data) on the left-hand side\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(x_data, cmap='gray')  # Display the grayscale image (assuming x_data is grayscale)\n",
    "    plt.title(f\"Example {i + 1} - X_train\")  # Set the title for the original image\n",
    "    \n",
    "    # Plot the corresponding mask (y_data) on the right-hand side\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(y_data, cmap='gray')  # Display the mask (adjust the colormap based on mask data)\n",
    "    plt.title(f\"Example {i + 1} - Y_train (Mask)\")  # Set the title for the mask\n",
    "    \n",
    "    plt.show()  # Show the plotted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# Define the U-Net architecture\n",
    "def unet(input_size=(256, 256, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Contracting path (Encoder)\n",
    "    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    bn1 = BatchNormalization(axis=3)(conv1)\n",
    "    bn1 = Activation('relu')(bn1)\n",
    "    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n",
    "    bn1 = BatchNormalization(axis=3)(conv1)\n",
    "    bn1 = Activation('relu')(bn1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n",
    "\n",
    "    # Contracting path (Encoder)\n",
    "    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n",
    "    bn2 = BatchNormalization(axis=3)(conv2)\n",
    "    bn2 = Activation('relu')(bn2)\n",
    "    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n",
    "    bn2 = BatchNormalization(axis=3)(conv2)\n",
    "    bn2 = Activation('relu')(bn2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n",
    "\n",
    "    # Contracting path (Encoder)\n",
    "    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n",
    "    bn3 = BatchNormalization(axis=3)(conv3)\n",
    "    bn3 = Activation('relu')(bn3)\n",
    "    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n",
    "    bn3 = BatchNormalization(axis=3)(conv3)\n",
    "    bn3 = Activation('relu')(bn3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n",
    "\n",
    "    # Contracting path (Encoder)\n",
    "    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n",
    "    bn4 = BatchNormalization(axis=3)(conv4)\n",
    "    bn4 = Activation('relu')(bn4)\n",
    "    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n",
    "    bn4 = BatchNormalization(axis=3)(conv4)\n",
    "    bn4 = Activation('relu')(bn4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n",
    "\n",
    "    # Contracting path (Encoder)\n",
    "    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n",
    "    bn5 = BatchNormalization(axis=3)(conv5)\n",
    "    bn5 = Activation('relu')(bn5)\n",
    "    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n",
    "    bn5 = BatchNormalization(axis=3)(conv5)\n",
    "    bn5 = Activation('relu')(bn5)\n",
    "\n",
    "    # Expansive path (Decoder)\n",
    "    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n",
    "    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n",
    "    bn6 = BatchNormalization(axis=3)(conv6)\n",
    "    bn6 = Activation('relu')(bn6)\n",
    "    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n",
    "    bn6 = BatchNormalization(axis=3)(conv6)\n",
    "    bn6 = Activation('relu')(bn6)\n",
    "\n",
    "    # Expansive path (Decoder)\n",
    "    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n",
    "    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n",
    "    bn7 = BatchNormalization(axis=3)(conv7)\n",
    "    bn7 = Activation('relu')(bn7)\n",
    "    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n",
    "    bn7 = BatchNormalization(axis=3)(conv7)\n",
    "    bn7 = Activation('relu')(bn7)\n",
    "\n",
    "    # Expansive path (Decoder)\n",
    "    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n",
    "    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n",
    "    bn8 = BatchNormalization(axis=3)(conv8)\n",
    "    bn8 = Activation('relu')(bn8)\n",
    "    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n",
    "    bn8 = BatchNormalization(axis=3)(conv8)\n",
    "    bn8 = Activation('relu')(bn8)\n",
    "\n",
    "    # Expansive path (Decoder)\n",
    "    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n",
    "    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n",
    "    bn9 = BatchNormalization(axis=3)(conv9)\n",
    "    bn9 = Activation('relu')(bn9)\n",
    "    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n",
    "    bn9 = BatchNormalization(axis=3)(conv9)\n",
    "    bn9 = Activation('relu')(bn9)\n",
    "\n",
    "    # Output layer\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n",
    "\n",
    "    # Create the U-Net model\n",
    "    return Model(inputs=[inputs], outputs=[conv10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a U-Net model using the defined architecture\n",
    "model = unet()\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs determines how many times the entire dataset is passed through the neural network during training\n",
    "EPOCHS = 100\n",
    "\n",
    "# Batch size defines the number of training examples processed in one iteration during training\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Learning rate sets the rate at which the model's parameters are updated during training\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Smooth parameter used in loss functions to prevent extreme values, often added to predicted and target values\n",
    "smooth = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    # Calculate intersection by summing the element-wise product of true and predicted masks\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "\n",
    "    # Calculate union by summing the elements in true and predicted masks separately\n",
    "    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n",
    "\n",
    "    # Compute Dice coefficient: (2 * intersection + smooth) / (union + smooth)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "    # Return Dice coefficient\n",
    "    return dice  # We usually minimize loss, so maximize (1 - dice)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    # Define loss as 1 minus the Dice coefficient to be used as the loss function\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Expand dimensions of training data to match the input shape of the model\n",
    "X_train_data = np.expand_dims(X_train_data, axis=-1)\n",
    "Y_train_data = np.expand_dims(Y_train_data, axis=-1)\n",
    "\n",
    "# Split the data into training and validation sets (80% training, 20% validation)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train_data, Y_train_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create a U-Net model with the specified input size\n",
    "model = unet(input_size=(256, 256, 1))\n",
    "\n",
    "# Calculate the decay rate for the learning rate schedule\n",
    "decay_rate = learning_rate / EPOCHS\n",
    "\n",
    "# Define the optimizer (Adam) with a specified initial learning rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model with the optimizer, loss function, and metrics for evaluation\n",
    "model.compile(optimizer=opt, loss=dice_coef_loss, metrics=[\"binary_accuracy\", dice_coef])\n",
    "\n",
    "# Train the model using the training data and validate on the validation set\n",
    "history = model.fit(\n",
    "    X_train, (Y_train > 0).astype(float),\n",
    "    validation_data=(X_val, (Y_val > 0).astype(float)),\n",
    "    steps_per_epoch=len(X_train) // 16,  # Number of steps per epoch (batch size)\n",
    "    epochs=EPOCHS,  # Number of training epochs\n",
    "    batch_size=16  # Batch size for training\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation set and output metrics\n",
    "val_metrics = model.evaluate(X_val, (Y_val > 0).astype(float), batch_size=16)\n",
    "print(f\"Validation Metrics: {dict(zip(model.metrics_names, val_metrics))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained U-Net model to a file path specified\n",
    "model.save('/kaggle/working/Unet_segmenter.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the weights of the trained U-Net model to a file path specified\n",
    "model.save_weights('/kaggle/working/Unet_segmenter_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2531491,
     "sourceId": 4296136,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
